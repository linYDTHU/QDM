trainer:
  target: trainer.TrainerQDMLPIPS

model:
  target: models.dit.QDM
  ckpt_path:  # add the path to the pre-trained model
  params:
    input_size: 128
    up_patch_size: 8
    down_patch_size: 2
    down_large_patch_size: 8
    in_channels: 3
    hidden_size: 768
    depth: 6
    num_heads: 12
    mlp_ratio: 4.0
    learn_sigma: False
    cond_lq: True
    lq_channels: 3


diffusion:
  target: models.script_util.create_masked_gaussian_diffusion
  params:
    sf: 4
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 15
    min_noise_level: 0.04
    kappa: 2.0
    weighted_mse: False
    predict_type: xstart
    timestep_respacing: ~
    scale_factor: 1.0
    normalize_input: True
    latent_flag: True

autoencoder:
  target: ldm.models.autoencoder.VQModelTorch
  ckpt_path: weights/autoencoder_vq_f4.pth
  use_fp16: True
  params:
    embed_dim: 3
    n_embed: 8192
    ddconfig:
      double_z: False
      z_channels: 3
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      padding_mode: zeros

degradation:
  sf: 4
  # the first degradation process
  resize_prob: [0.2, 0.7, 0.1]  # up, down, keep
  resize_range: [0.15, 1.5]
  gaussian_noise_prob: 0.5
  noise_range: [1, 30]
  poisson_scale_range: [0.05, 3.0]
  gray_noise_prob: 0.4
  jpeg_range: [30, 95]

  # the second degradation process
  second_order_prob: 0.5
  second_blur_prob: 0.8
  resize_prob2: [0.3, 0.4, 0.3]  # up, down, keep
  resize_range2: [0.3, 1.2]
  gaussian_noise_prob2: 0.5
  noise_range2: [1, 25]
  poisson_scale_range2: [0.05, 2.5]
  gray_noise_prob2: 0.4
  jpeg_range2: [30, 95]

data:
  train:
    type: combined
    params:
      local_lsdir_cache_dir: data/LSDIR/ 
      split: train
      limit_ffhq: 10000
      local_ffhq_dir: data/FFHQ-1024/
      local_flicker_dir: data/Flickr2K/
      local_div2k_dir: data/DIV2K/
      local_div8k_dir: data/DIV8K/
      local_outdoorscenetrain_dir: data/OST/
      
      transform_type: crop512

      blur_kernel_size: 21
      kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob: 0.1
      blur_sigma: [0.2, 3.0]
      betag_range: [0.5, 4.0]
      betap_range: [1, 2.0]

      blur_kernel_size2: 15
      kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob2: 0.1
      blur_sigma2: [0.2, 1.5]
      betag_range2: [0.5, 4.0]
      betap_range2: [1, 2.0]

      final_sinc_prob: 0.8

      use_hflip: True
      use_rot: False
      center_crop: False
  val:
    type: base
    params:
      dir_path: data/LSDIR_TEST/lq/
      im_exts: png
      extra_dir_path: data/LSDIR_TEST/gt/
      recursive: False
      length: 64

train:
  # mask threshold
  threshold: 0.00
  # wandb config
  run_name: realsr_qdm_b_lpips
  wandb_logging: True
  # learning rate
  lr: 5e-5                      # learning rate 
  lr_min: 5e-5                      # learning rate 
  loss_coef: [1.0, 0.1]
  stream_loss_coef: [1.0, 1.0]
  lr_schedule: cosin
  warmup_iterations: 0
  # dataloader
  batch: [64, 8]                
  microbatch: 8
  num_workers: 0
  prefetch_factor: None            
  # optimization settings
  weight_decay: 0               
  ema_rate: 0.999
  iterations: 50000            # total iterations
  # save logging
  save_freq: 5000
  log_freq: [200, 5000, 1]         # [training loss, training images, val images]
  local_logging: True           # manually save images
  tf_logging: False             # tensorboard logging
  # validation settings
  use_ema_val: True            
  val_freq: ${train.save_freq}
  val_y_channel: True
  # training setting
  use_amp: True                # amp training
  seed: 123456                 # random seed
  global_seeding: False
  # model compile
  compile:
    flag: False